{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AxiScan Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show an example of the AxiScan analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Code and Setup Plotting Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pymultinest\n",
    "import corner\n",
    "\n",
    "# Plotting Settings\n",
    "mpl.rcParams['figure.figsize'] = 20, 14 # default figure size\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Import MC generation and data analysis code The necessary modules\n",
    "from AxiScan import mc_gen # MC Generation\n",
    "from AxiScan import scan # Data Analysis\n",
    "import analysis_utilities as au # Convenient Utility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate Monte Carlo data for a scenario in which the majority of the dark matter is contained within a bulk halo following the Standard Halo Model parameters with a subdominant fraction contained within the Sagitarrius Stream. Although we have chosen to illustrate the analysis with a large signal strength, this can be easily adjusted. \n",
    "\n",
    "This is accomplished by seeding an instance (`generator`) of the Generator class in `mc_gen` with arguments detailed below. Data on the $i^\\text{th}$ day of data collection is generated by calling `generator.makePSD(i)`. The arguments for the Generator class are \n",
    "\n",
    "| Argument | Purpose |\n",
    "| ------------- | ------------- |\n",
    "| ma | ma/2pi is the axion mass [Hz] |\n",
    "| A | Proxy for the axion-photon coupling,  $A \\propto g_{a \\gamma \\gamma}^2$ |\n",
    "| v0_Halo | Velocity dispersion of the bulk halo [km/s] |\n",
    "| vDotMag_Halo | Speed of the sun with respect to the bulk halo [km/s]|\n",
    "| alpha_Halo | Bulk halo annual modulation scale, $\\alpha \\in [0, 1]$|\n",
    "| tbar_Halo | Date parameter for the bulk halo annual modultion [days] |\n",
    "| v0_Sub | Speed dispersion of the substructure halo [km/s] |\n",
    "| vDotMag_Sub | Speed of the sun with respect to the substructure halo [km/s]|\n",
    "| alpha_Sub | Substructure halo annual modulation scale, $\\alpha \\in [0, 1]$|\n",
    "| tbar_Sub | $\\qquad$ Date parameter for the substructure halo annual modultion [days] |\n",
    "| frac_Sub | Fraction of the axion DM in the substructure |\n",
    "| PSDback | Mean expected background Power Spectral Density |\n",
    "| freqs | Array of frequencies to calculate the PSD at [Hz] |\n",
    "\n",
    "The code generates data in the form of Power Spectral Densities (PSD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "###    Seed Values   ###\n",
    "########################\n",
    "c = 299798.452\n",
    "\n",
    "# Physics Parameters\n",
    "ma = 5.5e5*2*np.pi\n",
    "A = 500.0\n",
    "PSDback= 163539.36\n",
    "\n",
    "# Bulk SHM Parameters\n",
    "v0_Halo = 220.0\n",
    "vDotMag_Halo = 232.36\n",
    "alpha_Halo = .49\n",
    "tbar_Halo = 72.40\n",
    "\n",
    "# Sagitarrius Stream Parameters\n",
    "v0_Sub = 10.0\n",
    "vDotMag_Sub = 418.815\n",
    "alpha_Sub = .65903\n",
    "tbar_Sub = 279.51\n",
    "frac_Sub = 0.05\n",
    "\n",
    "# Data Output Size\n",
    "freqs = np.linspace(.99999, 1.00001, 500)*5.5e5\n",
    "PSD_Data = np.zeros((365, len(freqs)))\n",
    "\n",
    "collectionTime = 1/(freqs[1] - freqs[0])\n",
    "stacked_per_day = 86400 / collectionTime\n",
    "num_stacked = 365*stacked_per_day\n",
    "\n",
    "# Instantiate the data generator\n",
    "generator = mc_gen.Generator(ma, A, PSDback, v0_Halo, vDotMag_Halo, alpha_Halo, tbar_Halo,\n",
    "                             v0_Sub, vDotMag_Sub, alpha_Sub, tbar_Sub, frac_Sub, freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fill the `PSD_Data` array with each day of collected data. Data is generated assuming that that the entire 24 hours is used for data collection. If the collection time $T$ as inferred from the user-defined frequency resolution in `freqs` is less than 24 hours, then the data generated for each day is constructed as $24$ hours / $T$ stacked copies of data collections of duration $T$. \n",
    "\n",
    "We then stack data over the course of the year. The data stacked on the duration of a year is used for simple scans for an axion signal. The data stacked on the duration of the year may be used for more sophisticated scans and parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the PSD_Data array\n",
    "for i in range(365):\n",
    "    PSD_Data[i] = np.array(generator.makePSD(i))\n",
    "    \n",
    "    \n",
    "# Average over the days in the PSD_Data array for the simple scan\n",
    "Stacked_PSD_Data = np.mean(PSD_Data, axis = 0)\n",
    "\n",
    "plt.plot(freqs, Stacked_PSD_Data)\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('PSD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: The Simple Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we analyze the MC data when stacked over the duration of a year. In this analysis, we only scan over values of A and ma, and we will assume the Axion DM to follow a bulk Standard Halo Model profile with no substructure present. These steps can be repeated on real data.\n",
    "\n",
    "The anlysis is performed using `scan.TS_Scan`, which has the following arguments:\n",
    "\n",
    "| Argument | Purpose |\n",
    "| ------------- | ------------- |\n",
    "| Stacked_PSD_Data | Array of PSD data associated with the measurements when stacked over the duration of a year|\n",
    "| freqs | Array of frequencies associated with the data points [Hz] |\n",
    "|mass_TestSet | Range of axion masses scanned for in the analysis|\n",
    "| A_TestSet| Range of values of the A parameter scanned for at each mass| \n",
    "| PSDback | Mean expected background Power Spectral Density | \n",
    "| v0_Exp | Expected value of the SHM velocity dispersion [km/s]|\n",
    "| vObs_Exp | Expected value of the sun's speed with respect to the bulk SHM Halo [km/s]|\n",
    "| num_stacked | Total number of collections of duration T contained in the stacked data |\n",
    "\n",
    "The output of `scan.TS_Scan` is `TS_Array`, the value of the test statistic TS(`ma`, `A`) at each value of `ma` and `A` in `mass_TestSet` and `A_TestSet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Scan Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we expect to be searching for a bulk SHM distribution, we take SHM parameters `v0_Exp = 220.0` and `vObs_Exp = 232.36`. \n",
    "\n",
    "The set of masses in `mass_TestSet` is taken to be points on a log-spaced grid beginning at the mass corresponding to the minimum frequency for which we have data with a spacing factor of `1 + v0_Exp**2 /(2 c**2)`.\n",
    "\n",
    "The set of `A` in `A_TestSet` is determined by the necessary value of `A` of an injected signal expected to produce a 5$\\sigma$ detection. At a given mass-point, this value of A can be computed using [57] and [60] of 1711.xxxx. To ensure a sufficiently large range, we compute the maximum value of such an `A` over all mass, denoting this `A_max`. Then at each mass-point, we scan over values `-A_max` to `5 * A_max`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectation Parameters\n",
    "v0_Exp = 220.0\n",
    "vObs_Exp = 232.36\n",
    "\n",
    "# Construct the range of masses to scan over\n",
    "N_testMass = int(np.log(freqs[-1] / freqs[0])  / np.log(1. + v0_Exp**2. / 2. / c**2.))-3\n",
    "mass_TestSet = (freqs[0]*(1. + v0_Exp**2. / 2. / c**2.)**np.arange(N_testMass) * 2*np.pi)\n",
    "\n",
    "\n",
    "# Construct the range of signal strengths to scan over\n",
    "Sigma_A = au.getSigma_A(mass_TestSet, 365, 86400, v0_Exp, vObs_Exp, PSDback)\n",
    "N_indMasses = 4 * c**2 / (3 * v0_Exp**2) * np.log(np.amax(freqs)/np.amin(freqs))\n",
    "TS_Thresh = scipy.stats.norm.ppf(1 - (1-scipy.stats.norm.cdf(5))/N_indMasses)**2\n",
    "detection_Threshold = np.sqrt(TS_Thresh)*Sigma_A\n",
    "\n",
    "A_TestSet = np.linspace(-1.0, 5.0, 501)*np.amax(detection_Threshold)\n",
    "\n",
    "# Run the Scan\n",
    "TS_Array = np.array(scan.TS_Scan(Stacked_PSD_Data, freqs, mass_TestSet, A_TestSet, PSDback, v0_Exp, vObs_Exp, num_stacked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Scan Values and Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have obtained `TS_Array`, we can extract our maximum-likelihood estimates and the 95% limits of `A` at each `ma`. \n",
    "\n",
    "At a given `ma`, the maximum-likelihood estimate of A is given by \n",
    "\\begin{equation}\n",
    "\\hat A = \\text{argmax}_{A} TS(m_a, A)\n",
    "\\end{equation}\n",
    "\n",
    "At a given `ma`, the 95% limit on `A` is given by solving\n",
    "\\begin{equation}\n",
    "TS(m_a, A_{95\\%}) - TS(m_A, \\hat A) = 2.71, \\qquad A_{95\\%} \\geq \\hat A\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Limits = np.zeros(mass_TestSet.shape) # The expected 95% constraint\n",
    "A_Scans = np.zeros((mass_TestSet.shape)) # The TS maximizing value\n",
    "\n",
    "for i in range(len(A_Limits)):\n",
    "    # Naive TS maximizing value\n",
    "    A_Scans[i] = A_TestSet[np.argmax(TS_Array[i])]\n",
    "    \n",
    "    # Extracting the 95% constraint by a shift in the TS of 2.71\n",
    "    temp = np.copy(TS_Array[i])\n",
    "    temp[0:np.nanargmax(temp)] = float('nan')\n",
    "    temp -= np.nanmax(temp)\n",
    "    A_Limits[i] = A_TestSet[np.nanargmin(np.abs(temp+2.706))]\n",
    "    \n",
    "\n",
    "A_Limits = np.maximum(A_Limits, au.zScore(-1)*Sigma_A)\n",
    "A_Scans = np.maximum(0, A_Scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.title('Limits', size = 20)\n",
    "plt.plot(mass_TestSet, A_Limits)\n",
    "plt.fill_between(mass_TestSet, au.zScore(-1)*Sigma_A, au.zScore(2)*Sigma_A, color = 'yellow')\n",
    "plt.fill_between(mass_TestSet, au.zScore(-1)*Sigma_A, au.zScore(1)*Sigma_A, color = 'limegreen')\n",
    "plt.axvline(x=ma, ls = '--', c = 'black')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title('MLE Values', size = 20)\n",
    "plt.plot(mass_TestSet, A_Scans)\n",
    "plt.plot(mass_TestSet, detection_Threshold)\n",
    "plt.axvline(x=ma, ls = '--', c = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we plot the results of the simple scan for an axion signal. In the left panel, we plot the resulting 95% constraints (solid black) against the expected 95% constraints (dashed black) and 1$\\sigma$ (green) and 2$\\sigma$ (yellow) containment determined by the Asimov dataset according to [56] of 1711.xxxx. In the right panel, we plot at each mass-point the MLE of `A` (solid black) and the value of A at the threshold of a 5$\\sigma$ detection (dashed black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: The MultiNest Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have discovered a well-localized axion signal, we proceed to perform a MultiNest Scan over the data stacked at the level of a day. This will allow us to perform more detailed analysis of the signal parameters. For example, a MultiNest scan could be used to gain a more accurate estimate of `A` or `ma`, to study the annual modulation parameters, or to search for substructure. With sufficient computational resources, these could all be accomplished simultaneously. \n",
    "\n",
    "In the example below, we will perform a very basic MultiNest scan to gain a more accurate estimate of the `A` parameter under the assumption that all other signal parameters are known with perfect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Settings\n",
    "nlive = 500\n",
    "chains_dir = '/nfs/turbo/bsafdi/fosterjw/github/AxiScan/examples/chains/'\n",
    "\n",
    "pymultinest_options = {'importance_nested_sampling': False,\n",
    "                        'resume': False, 'verbose': True,\n",
    "                        'sampling_efficiency': 'model',\n",
    "                        'init_MPI': False, 'evidence_tolerance': 0.5,\n",
    "                        'const_efficiency_mode': False}\n",
    "\n",
    "\n",
    "# Parameters to Scan Over\n",
    "A_Prior = [.5*np.amax(A_Scans), 2*np.amax(A_Scans)]\n",
    "\n",
    "# Formatting the prior cube as required by MultiNest\n",
    "theta_min = [A_Prior[0]]\n",
    "theta_max = [A_Prior[1]]\n",
    "\n",
    "theta_interval = list(np.array(theta_max) - np.array(theta_min))\n",
    "n_params = len(theta_min) # number of parameters to fit for\n",
    "\n",
    "def prior_cube(cube, ndim=1, nparams=1):\n",
    "    \"\"\" Cube of priors - in the format required by MultiNest\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(ndim):\n",
    "        cube[i] = cube[i] * theta_interval[i] + theta_min[i]\n",
    "    return cube\n",
    "\n",
    "# Defining the likelihood function in terms of fixed and floated parameters\n",
    "def LL_Multinest(theta, ndim = 1, nparams = 1):\n",
    "    return scan.SHM_AnnualMod_ll(freqs, PSD_Data, ma, theta[0], v0_Halo, vDotMag_Halo,\n",
    "                                 alpha_Halo, tbar_Halo, PSDback, stacked_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MultiNest Scan\n",
    "pymultinest.run(LL_Multinest, prior_cube, n_params,\n",
    "                outputfiles_basename=chains_dir,\n",
    "                n_live_points=nlive, **pymultinest_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posteriors found by the MultiNest Scan\n",
    "chain_file = '/nfs/turbo/bsafdi/fosterjw/github/AxiScan/examples/chains/post_equal_weights.dat'\n",
    "chain = np.array(np.loadtxt(chain_file))[:, :-1]\n",
    "# Now make a triangle plot using corner\n",
    "corner.corner(chain, smooth=1.5, \n",
    "              labels = ['$A$', 'frac_Sub'], truths = [A, frac_Sub],\n",
    "              smooth1d=1, quantiles=[0.16, 0.5, 0.84], show_titles=True,\n",
    "              title_fmt='.2f', title_args={'fontsize': 14},\n",
    "              range=[1 for _ in range(chain.shape[1])],\n",
    "              plot_datapoints=False, verbose=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
